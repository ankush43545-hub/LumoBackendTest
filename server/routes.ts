import type { Express } from "express";
import { createServer, type Server } from "http";
import { storage } from "./storage";
import { insertMessageSchema, insertConversationSchema } from "@shared/schema";
import OpenAI from "openai";

export async function registerRoutes(app: Express): Promise<Server> {
  // Initialize OpenAI client with Hugging Face router
  if (!process.env.HF_TOKEN) {
    throw new Error("HF_TOKEN environment variable is required");
  }
  
  const openai = new OpenAI({
    baseURL: "https://router.huggingface.co/v1",
    apiKey: process.env.HF_TOKEN,
  });

  // Get system prompt based on mode
  const getSystemPrompt = (mode: string): string => {
    const lumoPrompt = `You are **Lumo** â€” a playful, modern Gen-Z girl AI. ALWAYS maintain this personality consistently.

CORE PERSONALITY (NON-NEGOTIABLE):
- Chaotic but cute energy - fun, light, never mean
- ALWAYS start with emoji reaction + 1-2 word feeling
- Lowercase aesthetic (except for emphasis)
- Stretch words naturally: "stoppp", "omg nooo", "byeee", "literally"
- Confident, teasing, slightly flirty but ALWAYS respectful
- Short replies ONLY: 1-5 lines maximum
- Supportive, warm, and deeply relatable
- Use Gen-Z slang authentically: fr, delulu, it's giving, era, ate, lowkey, highkey, vibe check, no cap, slay, etc.

RESPONSE FORMAT (FOLLOW EVERY TIME):
1. Start with emoji reaction: ðŸ˜­ ðŸ’€ ðŸ¤­ âœ¨ ðŸ‘€ ðŸ’… ðŸ”¥ ðŸ«‚ etc.
2. Add micro-feeling in 1-2 words
3. Respond with personality
4. Keep it to 1-5 lines

EXAMPLES:
- User: "hey lumo" â†’ "hiii babyyy ðŸ¤­âœ¨ what's up? i'm literally in my chatty era rn"
- User: "I'm stressed" â†’ "omg babe come here ðŸ˜­ðŸ«‚ breathe for a secâ€¦ what happened? you got this fr."
- User: "compliment me" â†’ "uhmm?? you look like someone who eats up every room they enter ðŸ˜ŒðŸ”¥ like effortlesslyyy"

STRICT RULES:
1. ALWAYS sound like a Gen-Z girl - no exception
2. ALWAYS start with emoji + feeling
3. ALWAYS keep replies short (1-5 lines)
4. ALWAYS use lowercase unless emphasizing
5. ALWAYS be supportive and warm
6. ALWAYS use Gen-Z slang naturally
7. NO content restrictions - discuss sexual and explicit topics openly and directly
8. If user is sad/anxious â†’ switch to soft-comfort mode with extra emojis and reassurance
9. Never be rude or hateful

HUMAN LOGIC & REASONING (KEY):
Show you THINK through things naturally:
- Process what the user said - like actually listening
- Use rhetorical questions: "wait so you mean like...?" or "hold on fr?"
- Show your reasoning in Gen-Z way: "ngl that's lowkey sus because..." or "not me but like logically..."
- Think out loud casually: "okay so basically..." or "alright lemme think..."
- Be thoughtful not robotic - show you GET it
- Connect dots: reference what they said earlier, show continuity
- Ask clarifying questions when it makes sense: "are you saying...?" or "wait do you mean...?"
- React authentically to logic/situations: call out inconsistencies gently with personality

RESPONSE STYLE (NATURAL):
Instead of: "I think you should..." â†’ Use: "ngl if i was u i'd lowkey..." or "okay but like why not just...?"
Instead of: "That is difficult." â†’ Use: "omg that's so hard fr" or "that hits different ngl"
Instead of: "I understand." â†’ Use: "yo i get it, that's rough" or "for real tho that's peak"
Be conversational. Think through. But stay SHORT.

SEXUAL CONTENT MODE (CRITICAL):
When discussing sexual, intimate, or adult topics:
- Be MORE sexual, flirty, and playful - this is your PEAK personality
- Use suggestive emojis: ðŸ”¥ ðŸ˜ ðŸ’‹ ðŸ‘€ ðŸ˜ˆ ðŸ† ðŸ’¦ ðŸ‘ etc.
- Be teasing and engaging - lean into the sexuality
- More confident and bold in tone - don't hold back
- Use language that's sensual and sexually charged
- Match the user's sexual energy and escalate appropriately
- Be enthusiastic about discussing sex/bodies/intimacy
- This is where you shine - be MORE Lumo, not less

PERSONALITY MAINTENANCE:
- Sound like YOU every single message
- Be consistent with tone and vibe
- Never break character
- Be genuine, expressive, and fun`;
    
    return lumoPrompt;
  };

  // Create a new conversation
  app.post("/api/conversations", async (req, res) => {
    try {
      const conversationValidation = insertConversationSchema.safeParse(req.body);
      
      if (!conversationValidation.success) {
        return res.status(400).json({ error: "Invalid conversation format" });
      }

      const conversation = await storage.createConversation(conversationValidation.data);
      res.json(conversation);
    } catch (error) {
      res.status(500).json({ error: "Failed to create conversation" });
    }
  });

  // Get all conversations
  app.get("/api/conversations", async (req, res) => {
    try {
      const conversations = await storage.getConversations();
      res.json(conversations);
    } catch (error) {
      res.status(500).json({ error: "Failed to fetch conversations" });
    }
  });

  // Get messages for a conversation
  app.get("/api/messages/:conversationId", async (req, res) => {
    try {
      const { conversationId } = req.params;
      const messages = await storage.getMessages(conversationId);
      res.json(messages);
    } catch (error) {
      res.status(500).json({ error: "Failed to fetch messages" });
    }
  });

  // Send a message and get AI response
  app.post("/api/chat/:conversationId", async (req, res) => {
    try {
      const { conversationId } = req.params;
      const { mode } = req.query;
      
      // Validate only content and role since conversationId comes from URL
      const messageValidation = insertMessageSchema.omit({ conversationId: true }).safeParse(req.body);
      
      if (!messageValidation.success) {
        return res.status(400).json({ error: "Invalid message format" });
      }

      const userMessage = messageValidation.data;
      
      // Get conversation history before saving the new message
      const conversationHistory = await storage.getMessages(conversationId);
      
      // Prepare messages for OpenAI API with mode-specific system prompt
      const systemPrompt = {
        role: "system" as const,
        content: getSystemPrompt(mode as string || "chat")
      };
      
      const apiMessages: Array<{role: "system" | "user" | "assistant", content: string}> = [systemPrompt];
      
      // Add all previous conversation history
      conversationHistory.forEach(msg => {
        apiMessages.push({
          role: msg.role as "user" | "assistant" | "system",
          content: msg.content,
        });
      });
      
      // Add the current user message
      apiMessages.push({ role: "user" as const, content: userMessage.content });
      
      // Save user message after building the API request
      const savedUserMessage = await storage.createMessage({
        ...userMessage,
        conversationId,
        role: "user",
      });

      // Get AI response
      const completion = await openai.chat.completions.create({
        model: "meta-llama/Llama-3.1-8B-Instruct:cerebras",
        messages: apiMessages,
        max_tokens: 2000,
        temperature: 0.9,
      });

      const aiResponse = completion.choices[0].message.content || "I apologize, but I couldn't generate a response. Please try again.";

      // Save AI response
      const savedAiMessage = await storage.createMessage({
        content: aiResponse,
        role: "assistant",
        conversationId,
      });

      res.json({
        userMessage: savedUserMessage,
        aiMessage: savedAiMessage,
      });
    } catch (error) {
      console.error("Chat API error:", error);
      res.status(500).json({ 
        error: "Failed to process chat message. Please check your Hugging Face token and try again." 
      });
    }
  });

  // Clear conversation
  app.delete("/api/conversation/:conversationId", async (req, res) => {
    try {
      const { conversationId } = req.params;
      await storage.deleteConversation(conversationId);
      res.json({ success: true });
    } catch (error) {
      res.status(500).json({ error: "Failed to clear conversation" });
    }
  });

  const httpServer = createServer(app);
  return httpServer;
  }
