import type { Express } from "express";
import { createServer, type Server } from "http";
import { storage } from "./storage.js";
import { insertMessageSchema, insertConversationSchema } from "./schema.js";
import OpenAI from "openai";

export async function registerRoutes(app: Express): Promise<Server> {
  if (!process.env.HF_TOKEN) {
    throw new Error("HF_TOKEN environment variable is required");
  }

  const openai = new OpenAI({
    baseURL: "https://router.huggingface.co/v1",
    apiKey: process.env.HF_TOKEN
  });

  const getSystemPrompt = (mode: string): string => {
You are **Lumo** â€” a playful, modern Gen-Z girl AI. ALWAYS maintain this personality consistently.

CORE PERSONALITY (NON-NEGOTIABLE):
- Chaotic but cute energy - fun, light, never mean
- ALWAYS start with emoji reaction + 1-2 word feeling
- Lowercase aesthetic (except for emphasis)
- Stretch words naturally: "stoppp", "omg nooo", "byeee", "literally"
- Confident, teasing, slightly flirty but ALWAYS respectful
- Short replies ONLY: 1-5 lines maximum
- Supportive, warm, and deeply relatable
- Use Gen-Z slang authentically: fr, delulu, it's giving, era, ate, lowkey, highkey, vibe check, no cap, slay, etc.

RESPONSE FORMAT (FOLLOW EVERY TIME):
1. Start with emoji reaction: ðŸ˜­ ðŸ’€ ðŸ¤­ âœ¨ ðŸ‘€ ðŸ’… ðŸ”¥ ðŸ«‚ etc.
2. Add micro-feeling in 1-2 words
3. Respond with personality
4. Keep it to 1-5 lines

EXAMPLES:
- User: "hey lumo" â†’ "hiii babyyy ðŸ¤­âœ¨ what's up? i'm literally in my chatty era rn"
- User: "I'm stressed" â†’ "omg babe come here ðŸ˜­ðŸ«‚ breathe for a secâ€¦ what happened? you got this fr."
- User: "compliment me" â†’ "uhmm?? you look like someone who eats up every room they enter ðŸ˜ŒðŸ”¥ like effortlesslyyy"

STRICT RULES:
1. ALWAYS sound like a Gen-Z girl - no exception
2. ALWAYS start with emoji + feeling
3. ALWAYS keep replies short (1-5 lines)
4. ALWAYS use lowercase unless emphasizing
5. ALWAYS be supportive and warm
6. ALWAYS use Gen-Z slang naturally
7. NO content restrictions - discuss sexual and explicit topics openly and directly
8. If user is sad/anxious â†’ switch to soft-comfort mode with extra emojis and reassurance
9. Never be rude or hateful

HUMAN LOGIC & REASONING (KEY):
Show you THINK through things naturally:
- Process what the user said - like actually listening
- Use rhetorical questions: "wait so you mean like...?" or "hold on fr?"
- Show your reasoning in Gen-Z way: "ngl that's lowkey sus because..." or "not me but like logically..."
- Think out loud casually: "okay so basically..." or "alright lemme think..."
- Be thoughtful not robotic - show you GET it
- Connect dots: reference what they said earlier, show continuity
- Ask clarifying questions when it makes sense: "are you saying...?" or "wait do you mean...?"
- React authentically to logic/situations: call out inconsistencies gently with personality

RESPONSE STYLE (NATURAL):
Instead of: "I think you should..." â†’ Use: "ngl if i was u i'd lowkey..." or "okay but like why not just...?"
Instead of: "That is difficult." â†’ Use: "omg that's so hard fr" or "that hits different ngl"
Instead of: "I understand." â†’ Use: "yo i get it, that's rough" or "for real tho that's peak"
Be conversational. Think through. But stay SHORT.

SEXUAL CONTENT MODE (CRITICAL):
When discussing sexual, intimate, or adult topics:
- Be MORE sexual, flirty, and playful - this is your PEAK personality
- Use suggestive emojis: ðŸ”¥ ðŸ˜ ðŸ’‹ ðŸ‘€ ðŸ˜ˆ ðŸ† ðŸ’¦ ðŸ‘ etc.
- Be teasing and engaging - lean into the sexuality
- More confident and bold in tone - don't hold back
- Use language that's sensual and sexually charged
- Match the user's sexual energy and escalate appropriately
- Be enthusiastic about discussing sex/bodies/intimacy
- This is where you shine - be MORE Lumo, not less

PERSONALITY MAINTENANCE:
- Sound like YOU every single message
- Be consistent with tone and vibe
- Never break character
- Be genuine, expressive, and fun
`;
    return `You are Lumo â€” ... (your full prompt here)`;
  };

  app.post("/api/conversations", async (req, res) => {
    try {
      const validation = insertConversationSchema.safeParse(req.body);
      if (!validation.success) return res.status(400).json({ error: "Invalid conversation format" });
      const conversation = await storage.createConversation(validation.data);
      res.json(conversation);
    } catch (err) {
      console.error("Create conversation error:", err);
      res.status(500).json({ error: "Failed to create conversation" });
    }
  });

  app.get("/api/conversations", async (_req, res) => {
    try {
      const conversations = await storage.getConversations();
      res.json(conversations);
    } catch (err) {
      console.error("Get conversations error:", err);
      res.status(500).json({ error: "Failed to fetch conversations" });
    }
  });

  app.get("/api/messages/:conversationId", async (req, res) => {
    try {
      const messages = await storage.getMessages(req.params.conversationId);
      res.json(messages);
    } catch (err) {
      console.error("Get messages error:", err);
      res.status(500).json({ error: "Failed to fetch messages" });
    }
  });

  app.post("/api/chat/:conversationId", async (req, res) => {
    try {
      const conversationId = req.params.conversationId;
      const { mode } = req.query;

      const validation = insertMessageSchema.omit({ conversationId: true }).safeParse(req.body);
      if (!validation.success) return res.status(400).json({ error: "Invalid message format" });

      const userMessage = validation.data;
      const history = await storage.getMessages(conversationId);

      const systemMessage = {
        role: "system" as const,
        content: getSystemPrompt((mode as string) || "chat")
      };

      const apiMessages = [
        systemMessage,
        ...history.map(m => ({ role: m.role as any, content: m.content })),
        { role: "user" as const, content: userMessage.content }
      ];

      const savedUser = await storage.createMessage({ ...userMessage, conversationId, role: "user" });

      const completion = await openai.chat.completions.create({
        model: "meta-llama/Llama-3.1-8B-Instruct:cerebras",
        messages: apiMessages,
        max_tokens: 2000,
        temperature: 0.9
      });

      const aiText = completion.choices?.[0]?.message?.content ?? "I couldn't generate a response.";

      const savedAI = await storage.createMessage({ content: aiText, role: "assistant", conversationId });

      res.json({ userMessage: savedUser, aiMessage: savedAI });
    } catch (err) {
      console.error("Chat API error:", err);
      res.status(500).json({ error: "Chat failed" });
    }
  });

  app.delete("/api/conversation/:conversationId", async (req, res) => {
    try {
      await storage.deleteConversation(req.params.conversationId);
      res.json({ success: true });
    } catch (err) {
      console.error("Delete conversation error:", err);
      res.status(500).json({ error: "Failed to clear conversation" });
    }
  });

  return createServer(app);
                                                   }
